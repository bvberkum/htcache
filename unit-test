#! /bin/bash
# 
# Unit tests originally for http-replicator, 
# adapted for htcache. Public domain?
# 

PORT=8090
NUM="$1"
PREFIX="/tmp/htcache-unittest$NUM"
URL_HTTP="www.w3.org:80/Protocols/HTTP/1.1/rfc2616bis/draft-lafon-rfc2616bis-03.txt"
URL_CHUNKED="jigsaw.w3.org:80/HTTP/ChunkedScript"
URL_FTP="ftp.debian.org:21/debian/doc/FAQ/debian-faq.en.pdf.gz"
PID="/tmp/htcache-unittest.$PORT"
RESOURCES='resources.db'

if test -z "$1"; then
  while $0 $((++i)); do true; done
  exit 0
fi

########## AUXILIARY FUNCTIONS ################################################

function startserver
{
  [ -e .coverage ] && rm .coverage
  test -e $PID && kill -int `cat $PID`
  rm -rf $PREFIX.*
  mkdir $PREFIX.cache
  if ! ./htcache -p $PORT -r $PREFIX.cache -f $RESOURCES -v -v $@ --daemon $PREFIX.log > $PID; then
    cat $PID
    rm $PID
    exit 1
  fi
}

function stripheaders
{
    mv $1 $1.tmp
    HEADERS_RECEIVED=
    while read L < $1.tmp
    do
        if [ -z "$()" ]; then
            HEADERS_RECEIVED=1
        fi
        if [ -n "$HEADERS_RECEIVED" ]; then
            echo $L | grep -v '^\(HTTP\|Connection\|Accept-\|P3P\|Via\|X-\|Date\)'
        else
            echo $L > $1
        fi
    done
}

if which wget > /dev/null; then
  function download
  {
    if test -e $PREFIX.$2; then
      WGETARGS="-c"
    fi
    # XXX: if dumping headers, some script needs to make sure only entity
    # headers are saved. Non-entity headers must be tested for  --save-headers  
    wget -q -O $PREFIX.$2 $1 $WGETARGS 1>&2
    #stripheaders $PREFIX.$2
  }
elif which curl > /dev/null; then
  function download
  {
    if test -e $PREFIX.$2; then
      CURLARGS="-C -"
    fi
    curl -o $PREFIX.$2 $CURLARGS $1 1>&2
    #-D  
    #stripheaders $PREFIX.$1
  }
else
  echo "error: no download tool available"
  exit 1
fi

function abort
{
  sleep $1
  if kill %%; then
    echo
    sleep 1
  else
    echo "error: download finished unexpectedly soon"
    exit 1
  fi
}

function touchfile
{
  FILENAME=$PREFIX.$1
  shift
  mkdir -p `dirname $FILENAME`
  touch $@ $FILENAME
}

function summary
{
  sleep .5
  #echo "============================================================================="
  echo " UNIT-TEST $NUM: $1"
  #echo " ---------------------------------------------------------------------------"
}

function check
{
  printf " * %-67s %5s %s\n" "$1" "$2" "$3"
}

function check_exists
{
  if test -e $PREFIX.$2; then
    check "$1" OK
  else
    check "$1" ERROR
  fi
}

if which md5 > /dev/null; then
  function checksum
  {
    md5 -q $1
  }
elif which md5sum cut > /dev/null; then
  function checksum
  {
    md5sum $1 | cut -d ' ' -f 1
  }
else
  echo "error: no checksum tool available"
  exit 1
fi

function check_equal
{
  if test ! -e $PREFIX.$2; then
    check "$1" ERROR "1st file missing" 
  elif test ! -e $PREFIX.$3; then
    check "$1" ERROR "2nd file missing" 
  elif test `checksum $PREFIX.$2` != `checksum $PREFIX.$3`; then
    check "$1" ERROR "files not equal"
  else
    check "$1" OK
  fi
}

function check_log
{
  if grep -q "$2" $PREFIX.log; then
    check "$1" OK
  else
    check "$1" ERROR
  fi
}

function stopserver
{
  #echo "============================================================================="
  #echo
  if test -e $PID; then
    kill -int `cat $PID`
    rm $PID
  fi
}

function coveragereport
{
  [ -z "$COVERAGE_PROCESS_START" ] && return
  echo Generating coverage report
  coverage combine
  coverage html
  #echo "============================================================================="
}

########## UNIT TESTS #########################################################

set -m
case $1 in
  1)
    startserver
    download http://$URL_HTTP out1
    http_proxy=localhost:$PORT download http://$URL_HTTP out2
    summary "DOWNLOADING NEW FILE"
    check_exists "file cached and finalized" cache/$URL_HTTP
    check_equal "separate download and served file are equal" out1 out2
    check_equal "cached and served file are equal" cache/$URL_HTTP out2
    stopserver
    ;;
  2)
    startserver
    http_proxy=localhost:$PORT download http://$URL_HTTP out & abort 1
    summary "LEAVING PARTIAL FILE IN CACHE"
    check_exists "file cached, not finalized" cache/$URL_HTTP.incomplete
    stopserver
    ;;
  3)
    startserver
    http_proxy=localhost:$PORT download http://$URL_HTTP out1
    http_proxy=localhost:$PORT download http://$URL_HTTP out2
    summary "SERVING FILE FROM CACHE"
    check_exists "first file cached and finalized" cache/$URL_HTTP
    check_log "second file served from cache" "Reading complete file from cache"
    check_equal "cached and first served file are equal" cache/$URL_HTTP out1
    check_equal "cached and second served file are equal" cache/$URL_HTTP out2
    stopserver
    ;;
  4)
    startserver
    download http://$URL_HTTP out & abort 1
    http_proxy=localhost:$PORT download http://$URL_HTTP out
    summary "RESUMING PARTIAL FILE BY CLIENT"
    check_log "received complete file" "Server responds HTTP/1.1 200 OK"
    check_log "served partial file" "HTCache responds HTTP/1.1 206 Partial Content"
    check_equal "cached and served file are equal" cache/$URL_HTTP out
    stopserver
    ;;
  5)
    startserver
    touchfile cache/$URL_HTTP -m -t 190112140000 
    http_proxy=localhost:$PORT download http://$URL_HTTP out
    summary "REDOWNLOADING CHANGED FILE"
    check_log "detected complete file in cache" "Checking complete file in cache"
    check_log "downloading new file" "Preparing new file in cache"
    check_equal "cached and served file are equal" cache/$URL_HTTP out
    stopserver
    ;;
  6)
    startserver
    http_proxy=localhost:$PORT download http://$URL_HTTP out1 & abort 1
    http_proxy=localhost:$PORT download http://$URL_HTTP out2
    summary "RESUMING PARTIAL UNCHANGED FILE IN CACHE"
    check_log "replicator asks for missing part" "Requesting resume of partial file in cache"
    check_log "received partial file" "Server responds HTTP/1.1 206 Partial Content"
    check_equal "cached and served file are equal" cache/$URL_HTTP out2
    stopserver
    ;;
  7)
    startserver
    touchfile cache/$URL_HTTP.incomplete
    http_proxy=localhost:$PORT download http://$URL_HTTP out
    summary "RESUMING PARTIAL CHANGED FILE IN CACHE"
    check_log "replicator asks for missing part" "Requesting resume of partial file in cache"
    check_log "received complete file" "Server responds HTTP/1.1 200 OK"
    check_equal "cached and served file are equal" cache/$URL_HTTP out
    stopserver
    ;;
  8)
    startserver
    http_proxy=localhost:$PORT download http://$URL_HTTP out1 > /dev/null & sleep 1
    http_proxy=localhost:$PORT download http://$URL_HTTP out2
    summary "JOINING DOWNLOADS"
    check_log "downloads are joined" "Joined running download"
    check_equal "cached and first served file are equal" cache/$URL_HTTP out1
    check_equal "cached and second served file are equal" cache/$URL_HTTP out2
    stopserver
    ;;
  9)
    startserver
    download http://$URL_CHUNKED out1
    http_proxy=localhost:$PORT download http://$URL_CHUNKED out2
    summary "DOWNLOADING NEW FILE, CHUNKED TRANSFER"
    check_equal "separate download and served file are equal" out1 out2
    check_log "server sends chunked data" "Transfer-Encoding: chunked"
    check_log "processing chunked data" "Switching to ChunkedDataResponse"
    check_equal "cached and served file are equal" cache/$URL_CHUNKED out2
    stopserver
    ;;
#  10)
#    startserver
#    download ftp://$URL_FTP out1
#    ftp_proxy=localhost:$PORT download ftp://$URL_FTP out2
#    summary "DOWNLOADING NEW FILE, FTP TRANSFER"
#    check_equal "separate download and served file are equal" out1 out2
#    check_equal "cached and served file are equal" cache/$URL_FTP out2
#    stopserver
#    ;;
#  11)
#    startserver
#    ftp_proxy=localhost:$PORT download ftp://$URL_FTP out1
#    ftp_proxy=localhost:$PORT download ftp://$URL_FTP out2
#    summary "SERVING FILE FROM CACHE, FTP TRANSFER"
#    check_exists "first file cached and finalized" cache/$URL_FTP
#    check_log "second file served from cache" "Reading complete file from cache"
#    check_equal "cached and first served file are equal" cache/$URL_FTP out1
#    check_equal "cached and second served file are equal" cache/$URL_FTP out2
#    stopserver
#    ;;
#  12)
#    startserver
#    ftp_proxy=localhost:$PORT download ftp://$URL_FTP out1 & abort 1
#    ftp_proxy=localhost:$PORT download ftp://$URL_FTP out2
#    summary "RESUMING PARTIAL UNCHANGED FILE IN CACHE, FTP TRANSFER"
#    check_log "replicator resumes file" "Resuming partial file in cache"
#    check_equal "cached and served file are equal" cache/$URL_FTP out2
#    stopserver
#    ;;
#  10)
#    startserver --limit 10
#    http_proxy=localhost:$PORT download http://$URL_HTTP out
#    summary "RATE CONTROL"
#    check "download speed; should be approximately 10240" CHECK
#    check_equal "cached and served file are equal" cache/$URL_HTTP out
#    stopserver
#    ;;
#  11)
#    startserver --static
#    http_proxy=localhost:$PORT download http://$URL_HTTP out1
#    http_proxy=localhost:$PORT download http://$URL_HTTP out2
#    summary "STATIC MODE"
#    check_log "serving directly from cache without consulting server" "Static mode; serving file directly from cache"
#    check_equal "cached and served file are equal" cache/$URL_HTTP out2
#    stopserver
#    ;;
#  12)
#    startserver --offline
#    http_proxy=localhost:$PORT download http://$URL_HTTP out
#    summary "OFF-LINE MODE"
#    check_log "refusing to connect to server" "AssertionError: operating in off-line mode"
#    stopserver
#    ;;

  10)
    coveragereport
    ;;

  *)
    exit 1
    ;;
esac

exit 0
# vim:sw=2:ts=2:et:
