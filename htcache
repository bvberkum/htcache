#! /usr/bin/env python
import os
import sys
import time
import weakref

from urlparse import urlparse


try:
    import coverage
    coverage.process_startup()
except ImportError, e:
    pass


import Params, Protocol, Request, Response, Resource, fiber



DOWNLOADS = weakref.WeakValueDictionary()
"""
Global set of download sessions, each being a request, protocol mapping.

Only one download per resource is needed, just the first request is kept here.
Each subsequent session will cannot overwrite the file, but can "join" the download 
by switching to the response fase.

XXX: This also allows local lookup of resources, ie. to rewrite the cache location
to locally stored data.
"""

Params.parse_droplist()
Params.parse_nocache()
Params.parse_joinlist()
#Params.parse_rewritelist()


### Descriptor/Cache Query static entry

# print_args
if Params.PRINT:
    if Params.PRINT == 'records':
#_ALLRECORDS:
        assert not (Params.PRUNE or Params.CHECK)
        descriptors = Resource.get_backend()
        Resource.print_info(*descriptors.keys())
    elif Params.PRINT_RECORD:
        Resource.print_info(*Params.PRINT_RECORD)
    elif Params.FIND_RECORDS:
        Resource.find_info(Params.FIND_RECORDS)
    elif Params.PRINT_MEDIA:
        Resource.print_media_list(*Params.PRINT_MEDIA)

### Descriptor/Cache Maintenance static entry

elif Params.CHECK == 'validate':
    #if Params.CHECK == 'validate':
    #    check = Resource.validate_cache
    pass

elif Params.CHECK == 'tree':
    check = Resource.check_tree
    if Params.PRUNE:
        descriptors = Resource.get_backend()
    else:
        descriptors = Resource.get_backend(main=False)
    pcount, rcount = 0, 0
    Params.log("Iterating paths in cache root location. ")
    for root, dirs, files in os.walk(Params.ROOT):
#    	rdir = os.path.join(Params.ROOT, root)
        for f in dirs + files:
            f = os.path.join(root, f)
            pcount += 1
            if f not in descriptors:
                if os.path.isfile(f):
                    Params.log("Missing descriptor for %s" % f)
                    if Params.PRUNE:
                        size = os.path.getsize(f)
                        if size < Params.MAX_SIZE_PRUNE:
                            os.unlink(f)
                            Params.log("Removed unknown file %s" % f)
                        else:
                            Params.log("Keeping %sMB" % (size / (1024 ** 2)))#, f))
                elif not (os.path.isdir(f) or os.path.islink(f)):
                    Params.log("Unrecognized path %s" % f)
            elif f in descriptors:
                rcount += 1
                descr = descriptors[f]
                if not len(descr) != 7:
                    Params.log("Unknown descriptor for %s" % descr)
                    continue
                uriref = descr[0][0]
                Params.log("Found resource %s" % uriref, threshold=1)
# XXX: hardcoded paths.. replace once Cache/Resource is properly implemented
                port = 80
                if len(descr[0]) != 1:
                    Params.log("Multiple references %s" % f)
                    continue
                urlparts = urlparse(uriref)
                hostname = urlparts.netloc
                pathname = urlparts.path[1:] 
# XXX: cannot reconstruct--, or should always normalize?
                if urlparts.query:
                    #print urlparts
                    pathname += '?'+urlparts.query
                hostinfo = hostname, port
                envelope = None, pathname, None
                cache = Resource.get_cache(hostinfo, envelope)
                #print 'got cache', cache.getsize(), cache.path
# end
    Params.log("Finished checking %s cache locations, found %s resources" % (
        pcount, rcount))
    descriptors.close()
    sys.exit(0)

elif Params.CHECK == 'check':
    check = Resource.check_cache
    #term = Resource.TerminalController()
    #print term.render('${YELLOW}Warning:${NORMAL}'), 'paper is crinkled'
    #pb = Resource.ProgressBar(term, 'Iterating descriptors')
    if Params.PRUNE:
        descriptors = Resource.get_backend()
    else:
        descriptors = Resource.get_backend(main=False)
    refs = descriptors.keys()
    count = len(refs)
    Params.log("Iterating %s descriptors" % count)
    for i, ref in enumerate(refs):
        if Params.VERBOSE > 2:
            print i, ref
        descr = descriptors[ref]
        urirefs, mediatype, d1, d2, meta, features = descr
        #progress = float(i)/count
        #pb.update(progress, ref)
# XXX: hardcoded paths.. replace once Cache/Resource is properly implemented
        port = 80
        if len(urirefs) != 1:
            Params.log("Multiple references %s" % ref)
            continue
        urlparts = urlparse(urirefs[0])
        hostname = urlparts.netloc
        pathname = urlparts.path[1:] 
# XXX: cannot reconstruct--, or should always normalize?
        if urlparts.query:
            #print urlparts
            pathname += '?'+urlparts.query
        hostinfo = hostname, port
        envelope = None, pathname, None
        cache = Resource.get_cache(hostinfo, envelope)
# end
        act = None
        if not check(cache, *descr):
            if not Params.PRUNE:
                continue
            act = True
            if cache.full() or cache.partial():
                path = cache.path
                if cache.partial():
                    path += '.incomplete'
                if os.path.getsize(path) > Params.MAX_SIZE_PRUNE:
                    if Params.INTERACTIVE:
                        pass
                    Params.log("Keeping %s" % path)
                    continue
                if os.path.isfile(path):
                    print 'size=', cache.getsize() / 1024**2
                    os.unlink(path)
                    Params.log("Deleted %s" % path)
                else:
                    Params.log("Unable to remove dir %s" % path)
            del descriptors[ref]
            Params.log("Removed %s" % cache.path)
    Params.log("Finished checking %s cache descriptors" % count)
    descriptors.close()
    #pb.clear()
    sys.exit(0)

if Params.MODE:
    for mode in Params.MODE:
        if mode == 'run-join':
            os.chdir(Params.ROOT)
            for root, dirs, files in os.walk(Params.ROOT):
                for d in dirs:
                    if d in ['.git']:
                        dirs.remove(d)
                for f in files:
                    fpath = os.path.join(root, f).replace(Params.ROOT,
                            '')
                    fpath2 = fpath.replace(':80','')
                    fpath3 = Resource.joinlist_rewrite(fpath2)
                    if fpath2 != fpath3:
                        print 'Renaming: ', fpath3, fpath
                        os.stat(fpath)
                        os.rename(fpath, fpath3)
                    #for line, regex in Params.JOIN:
                    #    if m:
                    #        m = regex.match(fpath)
                    #        print 'Match', fpath, m.groups()
    sys.exit(0)


# Global backend: the cache descriptors storage

backend = Params.descriptor_storage_type(Params.RESOURCES)


def HTCache( client, address ):

    Params.log('Accepted request from %s:%i' % address, 1)

    request = Request.HttpRequest()
    protocol = None
    while not request.Protocol:
        yield fiber.RECV( client, Params.TIMEOUT )
        request.recv( client )

    try:
        while request in DOWNLOADS:
            protocol = DOWNLOADS[ request ]
            if protocol.Response:
                if issubclass( protocol.Response, Response.DataResponse ):
                    Params.log('Joined running download')
                    break
                del DOWNLOADS[ request ]
            else:
                yield fiber.WAIT()
        else:
            Params.log('Switching to %s'% request.Protocol.__name__, 3)
            protocol = DOWNLOADS[ request ] = request.Protocol( request )
            server = protocol.socket()
            while not protocol.Response:
                if protocol.hasdata():
                    yield fiber.SEND( server, Params.TIMEOUT )
                    protocol.send( server )
                else:
                    yield fiber.RECV( server, Params.TIMEOUT )
                    protocol.recv( server )
        Params.log('Switching to %s'% protocol.Response.__name__, 2)
        response = protocol.Response( protocol, request )
        server = protocol.socket()
    except Exception:
        Params.log('Warning: Switching to ExceptionResponse')
        response = Response.ExceptionResponse( protocol, request )

    while not response.Done:
        if response.hasdata():
            yield fiber.SEND( client, Params.TIMEOUT )
            response.send( client )
        elif response.needwait():
            yield fiber.WAIT( response.needwait() )
        else:
            yield fiber.RECV( server, Params.TIMEOUT )
            response.recv( server )

    Params.log('Transaction successfully completed')

    #if protocol:
    #    if response.Done:
    response.finalize(client)
    #protocol.descriptors.close()


# XXX: more neat in fiber than here, move.
while True:
    try:
        fiber.spawn( HTCache, Params.PORT, Params.DEBUG, Params.LOG,
                Params.PID_FILE )
    except fiber.Restart, e:
        Resource.get_backend().close()
        for mod in (Params, Protocol, Request, Response, Resource, fiber):
            mod = reload(mod)
        Params.parse_droplist()
        Params.parse_nocache()
        Params.parse_joinlist()
    except Exception, e:
        Params.log(e)
        break

Resource.get_backend().close()

