#! /bin/bash
# 
# System tests originally for http-replicator. Adapted to test
# proxy functionality of htcache. Public domain.
# 

if test -z "$1"; then
  while $0 $((++i))
  do true
  done
  exit 0
else
  while test -n "$2"
  do
    $0 $1
    shift
  done
fi

PORT=8888
NUM="$1"
PREFIX="/tmp/htcache-systemtest$NUM"
LOG_LEVEL=7
ERR_LEVEL=7
LOG_FACILITIES="--log-facility protocol --log-facility cache"
URL_HTTP="www.w3.org/Protocols/HTTP/1.1/rfc2616bis/draft-lafon-rfc2616bis-03.txt"
URL_CHUNKED="jigsaw.w3.org/HTTP/ChunkedScript"
URL_FTP="ftp.debian.org:21/debian/doc/FAQ/debian-faq.en.pdf.gz"
PID="/tmp/htcache-systemtest.$PORT"
ABORT=0.6
WAIT=0.5

########## AUXILIARY FUNCTIONS ################################################

function clean
{
    [ -e .coverage ] && rm .coverage
    test -e $PID && kill -int `cat $PID`
    rm -rf $PREFIX*
}

function startserver
{
  echo "Starting server at port $PORT"
  for n in data cache
  do
    [ -d $PREFIX.$n ] || {
      mkdir $PREFIX.$n
    }
  done
  if ! ./htcache \
        -p $PORT -r $PREFIX.cache \
        --data-dir $PREFIX.data \
        --daemon $PREFIX.log \
        --log-level $LOG_LEVEL \
        --error-level $ERR_LEVEL \
          $LOG_FACILITIES \
        --pid-file $PID $*;
  then
    test -e $PID && rm $PID
    exit 1
  else
    echo Started server, running at PID $(cat $PID)
  fi
}

function htcache_command
{
  htcache \
    -r $PREFIX.cache \
    --data-dir $PREFIX.data \
    --daemon $PREFIX.log \
    $*
} 

function sortheaders
{
  mv $1 $1.tmp
  sort $1.tmp > $1
  rm $1.tmp
}

function splitheaders
{
  [ -e $PREFIX.$1.headers ] || {
    return
  }
  for f in $PREFIX.$1.entity.headers; # $PREFIX.$1.headers;
  do [ -e "$f" ] && rm $f; done
#  mv $PREFIX.$1 $PREFIX.tmp
#  ENVELOPE=$(head -n 1 $PREFIX.tmp)
#  HEADERS_RECEIVED=$([ "${ENVELOPE:0:8}" = "HTTP/1.1" ] && echo 0 || echo 1)
#  LINE=0
#  if [ $HEADERS_RECEIVED = 0 ]
#  then
#    while read L
#    do
#      LINE=$(($LINE + 1))
#      if [ $LINE = 1 ]
#      then
#        # dot not want to compare statusline b/c protocol version
#        echo $L > $PREFIX.$1.headers
#        continue
#      fi
#      if [ "$L" = "$(printf '\r\n')" ]; then
#        break
#      fi
#      STRIP=$(echo $L | grep -v '^\(Connection\|Accept-\|P3P\|Via\|X-\|Cache-\|Date\|Expires\)')
#      if [ -n "$STRIP" ]
#      then
#        # Keep entity headers for comparison
#        echo $L >> $PREFIX.$1.entity.headers
#      fi
#      # Keep all headers for other checks
#      echo $L >> $PREFIX.$1.headers
#    done < $PREFIX.tmp
#  fi
#  LINE=$(($LINE + 1))
#  # rest of lines is message contents
#  tail -n +$LINE $PREFIX.tmp > $PREFIX.$1

  while read L
  do
    STRIP=$(echo $L | grep -v '^\(Connection\|Accept-\|P3P\|Via\|X-\|Cache-\|Date\|Expires\)')
    if [ -n "$STRIP" ]
    then
        # Keep entity headers for comparison
        echo $L >> $PREFIX.$1.entity.headers
    fi
  done < $PREFIX.$1.headers

  sortheaders $PREFIX.$1.headers
  sortheaders $PREFIX.$1.entity.headers

  [ -e $PREFIX.tmp ] && rm $PREFIX.tmp
}

# XXX: could not figure out a way to make wget save (headers) for non 200
#if which wget > /dev/null; then
#  function download
#  {
#    echo Downloading $2 $1
#    if test -e $PREFIX.$2; then
#      WGETARGS="-c"
#    fi
#    wget --save-headers -O $PREFIX.$2 $1 $WGETARGS
#    #1>&2
#    splitheaders $2
#  }
#el
if which curl > /dev/null; then
  function download
  {
    if test -e $PREFIX.$2;
    then
      echo "Resuming unfinished download at $(stat -c "%s" $PREFIX.$2) bytes"
      CURLARGS="-C - "
    fi
    curl $CURLARGS -s -S -o $PREFIX.$2 --dump-header $PREFIX.$2.headers $1  1>&2
    echo "Finished file download at $(stat -c "%s" $PREFIX.$2) bytes"
    splitheaders $2
  }
else
  echo "error: no download tool available, install curl"
  exit 1
fi

function abort
{
  sleep $1
  if kill %% 2> /dev/null; then
    #if kill -int $(cat $PID); then
    echo
    sleep 1
  else
    echo "error: download finished unexpectedly soon"
    exit 1
  fi
}

function touchfile
{
  FILENAME=$PREFIX.$1
  shift
  mkdir -p `dirname $FILENAME`
  touch $@ $FILENAME
}

function summary
{
  echo
  echo "============================================================================="
  echo " UNIT-TEST $NUM: $1"
  echo " ---------------------------------------------------------------------------"
}

function check
{
  printf " * %-67s %5s %s\n" "$1" "$2" "$3"
}

function check_exists
{
  if test -e $PREFIX.$2; then
    check "$1" PASSED
  else
    check "$1" ERROR
  fi
}

function check_url_cached
{
  if htcache_command --print-location $2 > /dev/null; then
    check "$1" PASSED
  else
    check "$1" ERROR
  fi
}

if which md5 > /dev/null; then
  function checksum
  {
    md5 -q $1
  }
elif which md5sum cut > /dev/null; then
  function checksum
  {
    md5sum $1 | cut -d ' ' -f 1
  }
else
  echo "error: no checksum tool available"
  exit 1
fi

function check_equal
{
  if test ! -e $PREFIX.$2; then
    check "$1" ERROR "1st missing: $2" 
  elif test ! -e $PREFIX.$3; then
    check "$1" ERROR "2nd missing: $3"
  elif test `checksum $PREFIX.$2` != `checksum $PREFIX.$3`; then
    if test -n "$4";
    then
      check "$1" ERROR "not equal:"
      comm -3 $PREFIX.$2 $PREFIX.$3
    else
      check "$1" ERROR "not equal"
    fi
  else
    check "$1" PASSED
  fi
}

function check_log
{
  if grep $3 -q "$2" $PREFIX.log; then
    check "$1" PASSED
  else
    check "$1" ERROR
  fi
}

function check_log_errors
{
    check_log "Clean log" "error\|exception\|failure\|\<warn\>\|\<crit\>" -iv
}

function check_headers
{
  if grep -q "$3" $PREFIX.$1.headers > /dev/null; then
    check "$2" PASSED
  else
    check "$2" "ERROR"
  fi
}

function stopserver
{
  if test -e $PID
  then
    if kill -int `cat $PID`
    then
        echo "Interrupted server at $(cat $PID)"
    else
        echo "Error closing server normally"
    fi
    rm $PID
  fi
}

function coveragereport
{
  [ -z "$COVERAGE_PROCESS_START" ] && return
  echo Generating coverage report
  coverage combine
  coverage html
}

########## UNIT TESTS #########################################################

set -m
case $1 in
  1)
    summary "DOWNLOADING NEW FILE"

    clean
    startserver
    download http://$URL_HTTP out1
    http_proxy=localhost:$PORT download http://$URL_HTTP out2
    stopserver

    check_exists "file cached and finalized" cache/$URL_HTTP
    check_url_cached "record exists" http://$URL_HTTP
    check_equal "separate download and served file are equal" out1 out2
    check_equal "cached and served file are equal" cache/$URL_HTTP out2
    check_equal "normal and served entity headers are equal" out1.entity.headers out2.entity.headers
    check_headers out2 "served HTTP v1.1 OK" "HTTP/1.1 200 "
    check_headers out2 "served via proxy" "Via:\ [a-z\.-]\+:$PORT"
    check_log_errors
    ;;
  2)
    summary "LEAVING PARTIAL FILE IN CACHE"

    clean
    startserver
    download http://$URL_HTTP normal
    http_proxy=localhost:$PORT download http://$URL_HTTP cached & abort $WAIT
    splitheaders cached
    stopserver

    check_log "Aborted client read" "Error writing to client"
    check_url_cached "record exists" http://$URL_HTTP

    #htcache_command --print-location http://$URL_HTTP
    INCOMPLETE=$(htcache_command --print-location http://$URL_HTTP)
    P=$(( ${#PREFIX} + 7 ))
    check_exists "file cached, not finalized" cache/${INCOMPLETE:$P}
    # XXX: No headers are ever present, need to check if older versions did
    #    splitheaders cached
    #    check_equal "headers are equal" normal.entity.headers cached.entity.headers
    #    check_headers cached "served HTTP v1.1 OK" "HTTP/1.1 200 "
    check_log_errors
    ;;
  3)
    summary "SERVING FILE FROM CACHE"

    clean
    startserver
    download http://$URL_HTTP out
    http_proxy=localhost:$PORT download http://$URL_HTTP out1
    sleep 4
    http_proxy=localhost:$PORT download http://$URL_HTTP out2
    stopserver
    
    check_exists "first file cached and finalized" cache/$URL_HTTP
    check_url_cached "record exists" http://$URL_HTTP
    check_equal "cached and normal file are equal" cache/$URL_HTTP out
    check_headers out1 "first file served via proxy" "Via:\ [a-z\.-]\+:$PORT"
    check_headers out2 "second file served via proxy" "Via:\ [a-z\.-]\+:$PORT"
    check_headers out1 "first file served HTTP v1.1 OK" "HTTP/1.1 200 "
    check_headers out2 "second file served HTTP v1.1 OK" "HTTP/1.1 200 "
    check_log "first file stored in cache" "Preparing new file in cache"
    check_log "second file served from cache" "Reading complete file from cache"
    check_equal "cached and first served file are equal" cache/$URL_HTTP out1
    check_equal "cached and second served file are equal" cache/$URL_HTTP out2
    check_equal "normal and first served headers are equal" out.entity.headers out1.entity.headers true
    check_equal "normal and second served headers are equal" out.entity.headers out2.entity.headers true
    check_log_errors
    ;;

  4)
    summary "RESUMING PARTIAL FILE BY CLIENT"

    clean
    download http://$URL_HTTP out
    download http://$URL_HTTP out1 & abort $ABORT
    splitheaders out1
    startserver
    cp $PREFIX.out1 $PREFIX.out2
    http_proxy=localhost:$PORT download http://$URL_HTTP out2
    sleep $WAIT
    stopserver
    sleep $WAIT

    check_log "received complete file" "Server responds HTTP/1.1 200 OK"
    check_log "served partial file" "HTCache responds HTTP/1.1 206 Partial Content"
#    check_headers out2 "served HTTP v1.1 OK" "HTTP/1.1 200 OK"
    check_equal "cached and served file are equal" out out2
    check_log_errors
    ;;
  5)
# XXX: cannot test without descriptor of aux. command to load descriptor into DB
#    summary "REDOWNLOADING CHANGED FILE"
#    startserver
#    touchfile cache/$URL_HTTP -m -t 190112140000 
#    http_proxy=localhost:$PORT download http://$URL_HTTP out
#    check_log "detected complete file in cache" "Checking complete file in cache"
#    check_log "downloading new file" "Preparing new file in cache"
#    check_equal "cached and served file are equal" cache/$URL_HTTP out
#    check_headers out "served HTTP v1.1 OK" "HTTP/1.1 200 "
#    stopserver
    ;;
  6)
    summary "RESUMING PARTIAL UNCHANGED FILE IN CACHE"
    
    clean
    startserver
    http_proxy=localhost:$PORT download http://$URL_HTTP out1 & abort $ABORT
#    echo $(stat -c "%s" $PREFIX.out1) bytes
#    splitheaders out1
    http_proxy=localhost:$PORT download http://$URL_HTTP out2
    stopserver
    check_log "htcache asks for missing part" "Requesting resume of partial file in cache"
    check_log "received partial file" "Server responds HTTP/1.1 206 Partial Content"
    check_log "finalized file" "Finalized"
    check_equal "cached and served file are equal" cache/$URL_HTTP out2
    check_log_errors
    ;;
  7)
    summary "RESUMING PARTIAL CHANGED FILE IN CACHE"
    startserver
    touchfile cache/$(echo $URL_HTTP | sed 's/.txt$/.incomplete.txt/' )
    http_proxy=localhost:$PORT download http://$URL_HTTP out
    stopserver
    check_log "htcache asks for missing part" "Requesting resume of partial file in cache"
    check_log "received complete file" "Server responds HTTP/1.1 200 OK"
    check_equal "cached and served file are equal" cache/$URL_HTTP out
    check_log_errors
    ;;
  8)
    summary "JOINING DOWNLOADS"
    
    clean
    startserver
    http_proxy=localhost:$PORT download http://$URL_HTTP out1 > /dev/null & sleep $WAIT
    http_proxy=localhost:$PORT download http://$URL_HTTP out2
    stopserver
    check_log "downloads are joined" "Joined running download"
    check_equal "cached and first served file are equal" cache/$URL_HTTP out1
    check_equal "cached and second served file are equal" cache/$URL_HTTP out2
    check_log_errors
    ;;
  9)
    summary "DOWNLOADING NEW FILE, CHUNKED TRANSFER"
    
    clean
    startserver
    download http://$URL_CHUNKED out1
    http_proxy=localhost:$PORT download http://$URL_CHUNKED out2
    stopserver
    check_equal "separate download and served file are equal" out1 out2
    check_log "server sends chunked data" "Transfer-Encoding: chunked"
    check_log "processing chunked data" "Switching to ChunkedDataResponse"
    check_equal "cached and served file are equal" cache/$URL_CHUNKED out2
    check_log_errors
    ;;
  10)
    summary "FILTERED PROXY RESPONSE"
    
    clean
    echo "www\.w3\.org\/Protocols\/HTTP.*" > $PREFIX-rules.drop
    startserver --drop $PREFIX-rules.drop
    http_proxy=localhost:$PORT download http://$URL_HTTP out
    stopserver
    check_log "blocked request to server" "Switching to BlockedContentResponse"
    check_headers out "server sent 403" "HTTP/1.1 403 Dropped By Proxy"
    check_headers out.entity "served HTML" "Content-Type: text\/html"
    check_log_errors
    ;;
  11)
    summary "BLIND PROXY RESPONSE"
    
    clean
    echo "www\.w3\.org\/Protocols\/HTTP.*" > $PREFIX-rules.nocache
    startserver --nocache $PREFIX-rules.nocache
    http_proxy=localhost:$PORT download http://$URL_HTTP out
    stopserver
    check_log "blocked request to server" "Switching to BlindResponse"
    check_headers out "served HTTP v1.* OK" "HTTP/1.* 200 "
    check_log_errors
    ;;
  12)
    summary "DOWNLOADING NEW FILE, FTP TRANSFER"
    clean
    startserver
    download ftp://$URL_FTP out1
    ftp_proxy=localhost:$PORT download ftp://$URL_FTP out2
    stopserver
    check_equal "separate download and served file are equal" out1 out2
    check_equal "cached and served file are equal" cache/$URL_FTP out2
    ;;
  13)
    summary "SERVING FILE FROM CACHE, FTP TRANSFER"
    clean
    startserver
    ftp_proxy=localhost:$PORT download ftp://$URL_FTP out1
    ftp_proxy=localhost:$PORT download ftp://$URL_FTP out2
    stopserver
    check_exists "first file cached and finalized" cache/$URL_FTP
    check_log "second file served from cache" "Reading complete file from cache"
    check_equal "cached and first served file are equal" cache/$URL_FTP out1
    check_equal "cached and second served file are equal" cache/$URL_FTP out2
    ;;
  14)
    summary "RESUMING PARTIAL UNCHANGED FILE IN CACHE, FTP TRANSFER"
    clean
    startserver
    ftp_proxy=localhost:$PORT download ftp://$URL_FTP out1 & abort $WAIT
    ftp_proxy=localhost:$PORT download ftp://$URL_FTP out2
    stopserver
    check_log "htcache resumes file" "Resuming partial file in cache"
    check_equal "cached and served file are equal" cache/$URL_FTP out2
    ;;
  15)
    summary "RATE CONTROL"
    clean
    startserver --limit 10
    http_proxy=localhost:$PORT download http://$URL_HTTP out
    stopserver
    check "download speed; should be approximately 10240" CHECK
    check_equal "cached and served file are equal" cache/$URL_HTTP out
    ;;
  16)
    summary "STATIC MODE"
    clean
    startserver --static
    http_proxy=localhost:$PORT download http://$URL_HTTP out1
    http_proxy=localhost:$PORT download http://$URL_HTTP out2
    stopserver
    check_log "serving directly from cache without consulting server" "Static mode; serving file directly from cache"
    check_equal "cached and served file are equal" cache/$URL_HTTP out2
    ;;
  17)
    summary "OFF-LINE MODE"
    clean
    startserver --offline
    http_proxy=localhost:$PORT download http://$URL_HTTP out
    stopserver
    check_log "refusing to connect to server" "AssertionError: operating in off-line mode"
    ;;

  18)
    coveragereport
    ;;

  *)
    exit 1
    ;;

esac

exit 0
# vim:sw=2:ts=2:et:
